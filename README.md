# AWESOME-MER

 :memo: A reading list focused on Multimodal Emotion Recognition (MER)  :ear: :lips: :eyes: :speech_balloon:

***

:high_brightness: [Datasets](#datasets)

:high_brightness: [Projects](#projects)

:high_brightness: [Related Reviews](#related-reviews)

:high_brightness: [Multimodal Emotion Recognition (MER)](#multimodal-emotion-recognition)

## Datasets

- [EMOTIC Dataset](http://sunai.uoc.edu/emotic/)
- [Multimodal Spontaneous Emotion Database (BP4D+)](http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html)
- [LIRIS-ACCEDE Database](https://liris-accede.ec-lyon.fr/)
- [SEMAINE Database](https://ibug.doc.ic.ac.uk/resources/semaine-database2/)
- [IEMOCAP Database](https://sail.usc.edu/iemocap/)
- [CMU-MOSEI](https://github.com/A2Zadeh/CMU-MultimodalSDK)
- [EmotiW Database](https://sites.google.com/view/emotiw2020)
- [MAHNOB-HCI](https://mahnob-db.eu/hci-tagging/)
- [ASCERTAIN Dataset](http://mhug.disi.unitn.it/wp-content/ASCERTAIN/ascertain.html)
- [eNTERFACE Dataset](http://enterface.net/)

## Projects

- [CMU Multimodal SDK](https://github.com/A2Zadeh/CMU-MultimodalSDK)
- [Real-Time Multimodal Emotion Recognition](https://github.com/maelfabien/Multimodal-Emotion-Recognition) 
- [MixedEmotions Toolbox](https://github.com/MixedEmotions/MixedEmotions)
- [End-to-End Multimodal Emotion Recognition](https://github.com/tzirakis/Multimodal-Emotion-Recognition)

## Related Reviews

- (Information Fusion17) A review of affective computing: From unimodal analysis to multimodal fusion [[paper](https://ww.sentic.net/affective-computing-review.pdf)] 

- (Image and Vision Computing17) A survey of multimodal sentiment analysis [[paper](https://ibug.doc.ic.ac.uk/media/uploads/documents/multi_modal.pdf)] 
- (ACM Computing Surveys15) A Review and Meta-Analysis of Multimodal Affect Detection Systems [[paper](https://dl.acm.org/doi/10.1145/2682899)] 

## Multimodal Emotion Recognition

（:white_small_square: indicates a specific modality）

### :small_orange_diamond: CVPR

- (2020) EmotiCon: Context-Aware Multimodal Emotion Recognition using Frege’s Principle [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Mittal_EmotiCon_Context-Aware_Multimodal_Emotion_Recognition_Using_Freges_Principle_CVPR_2020_paper.pdf)] [:white_small_square:Faces/Gaits :white_small_square:Background :white_small_square:Social interactions]
- (2017) Emotion Recognition in Context [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Kosti_Emotion_Recognition_in_CVPR_2017_paper.pdf)] [:white_small_square:Face :white_small_square:Context]

### :small_orange_diamond: ICCV

- (2019) Context-Aware Emotion Recognition Networks [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Lee_Context-Aware_Emotion_Recognition_Networks_ICCV_2019_paper.pdf)] [:white_small_square:Faces :white_small_square:Context]
- (2017) A Multimodal Deep Regression Bayesian Network for Affective Video Content Analyses [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Gan_A_Multimodal_Deep_ICCV_2017_paper.pdf)] [:white_small_square:Visual :white_small_square:Audio]

### :small_orange_diamond: AAAI

- (2020) M3ER: Multiplicative Multimodal Emotion Recognition Using Facial, Textual, and Speech Cues [[paper](https://arxiv.org/pdf/1911.05659.pdf)] [:white_small_square:Face :white_small_square:Speech :white_small_square:Text ​]
- (2020) An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos [[paper](https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhaoS.7155.pdf)] [:white_small_square:Visual :white_small_square:Audio ]
- (2019) Multi-Interactive Memory Network for Aspect Based Multimodal Sentiment Analysis [[paper](https://www.aaai.org/ojs/index.php/AAAI/article/view/3807)] [:white_small_square:Visual :white_small_square:Text ]

- (2019) VistaNet: Visual Aspect Attention Network for Multimodal Sentiment Analysis [[paper](https://www.aaai.org/ojs/index.php/AAAI/article/view/3799)] [:white_small_square:Visual :white_small_square:Text ]
- (2019) Cooperative Multimodal Approach to Depression Detection in Twitter [[paper](https://www.aaai.org/ojs/index.php/AAAI/article/view/3775)] [:white_small_square:Visual :white_small_square:Text ]
- (2014) Predicting Emotions in User-Generated Videos [[paper](http://www.yugangjiang.info/publication/aaai14-emotions.pdf)] [:white_small_square:Visual :white_small_square:Audio :white_small_square:Attribute ]

### :small_orange_diamond: IJCAI

- (2019) DeepCU: Integrating both Common and Unique Latent Information for Multimodal Sentiment Analysis [[paper](https://arxiv.org/pdf/1911.05659.pdf)] [:white_small_square:Face :white_small_square:Audio :white_small_square:Text ]
- (2019) Adapting BERT for Target-Oriented Multimodal Sentiment Classification [[paper](https://www.ijcai.org/Proceedings/2019/0751.pdf)] [:white_small_square:Image :white_small_square:Text ]
- (2018) Personality-Aware Personalized Emotion Recognition from Physiological Signals [[paper](https://www.ijcai.org/Proceedings/2018/0230.pdf)] [:white_small_square:Personality :white_small_square: Physiological signals ]
- (2015) Combining Eye Movements and EEG to Enhance Emotion Recognition  [[paper](https://www.ijcai.org/Proceedings/15/Papers/169.pdf)] [:white_small_square:EEG :white_small_square:Eye movements ]

### :small_orange_diamond: ACM MM

- (2019) Emotion Recognition using Multimodal Residual LSTM Network  [[paper](https://haotang1995.github.io/files/ACM-MM-19.pdf)] [:white_small_square: EEG :white_small_square:Other physiological signals ]
- (2019) Multimodal Deep Denoise Framework for Affective Video Content Analysis [[paper](https://dl.acm.org/doi/10.1145/3343031.3350997)] [:white_small_square:Face :white_small_square:Body gesture:white_small_square:Voice:white_small_square: Physiological signals]

### :small_orange_diamond: WACV

- (2016) Multimodal emotion recognition using deep learning architectures [[paper](https://ieeexplore.ieee.org/document/7477679)] [:white_small_square:Visual :white_small_square:Audio]

### :small_orange_diamond: FG

- (2020) Multimodal Deep Learning Framework for Mental Disorder Recognition  [[paper](https://www.cl.cam.ac.uk/~mmam3/pub/FG2020_Multimodal_Deep_Learning_Framework_for_Mental_Disorder_Recognition.pdf)] [:white_small_square:Visual :white_small_square:Audio :white_small_square:Text]

- (2019) Audio-Visual Emotion Forecasting: Characterizing and Predicting Future Emotion Using Deep Learning  [[paper](https://ieeexplore.ieee.org/document/8756599)] [:white_small_square:Face :white_small_square:Speech]

### :small_orange_diamond: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)

- (2020) Context Based Emotion Recognition using EMOTIC Dataset  [[paper](https://arxiv.org/abs/2003.13401)] [:white_small_square:Face :white_small_square:Context]

### :small_orange_diamond:  IEEE Transactions on Cybernetics 

- (2019) EmotionMeter: A Multimodal Framework for Recognizing Human Emotions  [[paper](https://ieeexplore.ieee.org/document/8283814)] [:white_small_square:EEG :white_small_square:Eye movements]

### :small_orange_diamond: IEEE Transactions on Multimedia

- (2018) Multimodal Framework for Analyzing the Affect of a Group of People  [[paper](https://ieeexplore.ieee.org/document/8323249)] [:white_small_square:Face:white_small_square:Upper body:white_small_square: Scene]

### :small_orange_diamond: IEEE Transactions on Affective Computing

- (2019) Audio-Visual Emotion Recognition in Video Clips  [[paper](https://ieeexplore.ieee.org/document/7945502)] [:white_small_square:Visual :white_small_square:Audio]
- (2018) Combining Facial Expression and Touch for Perceiving Emotional Valence [[paper](https://ieeexplore.ieee.org/document/7752812)] [:white_small_square:Face :white_small_square:Touch stimuli]
- (2016) Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection [[paper](https://ieeexplore-ieee-org.eproxy.lib.hku.hk/document/7112127)] [:white_small_square:Face :white_small_square:EEG signals]
- (2012) Multimodal Emotion Recognition in Response to Videos  [[paper](https://ieeexplore.ieee.org/document/6095505)] [:white_small_square:Eye gaze :white_small_square:EEG signals]

### :small_orange_diamond: Others

- (IEEE Journal of Selected Topics in Signal Processing 2017) End-to-End Multimodal Emotion Recognition Using Deep Neural Networks [[paper](https://arxiv.org/pdf/1704.08619.pdf)] [:white_small_square:Visual :white_small_square:Audio]

